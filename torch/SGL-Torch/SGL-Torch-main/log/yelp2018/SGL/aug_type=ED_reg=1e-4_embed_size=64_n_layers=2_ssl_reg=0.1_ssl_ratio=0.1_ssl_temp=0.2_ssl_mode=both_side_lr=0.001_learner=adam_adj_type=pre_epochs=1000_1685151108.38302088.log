2023-05-27 09:31:48.393: my pid: 16128
2023-05-27 09:31:48.393: model: model.general_recommender.SGL
2023-05-27 09:31:48.393: Dataset statistics:
Name: yelp2018
The number of users: 31668
The number of items: 38048
The number of ratings: 1561406
Average actions of users: 49.31
Average actions of items: 41.04
The sparsity of the dataset: 99.870412%

The number of training: 1237259
The number of validation: 0
The number of testing: 324147
2023-05-27 09:31:48.394: NeuRec:[NeuRec]:
recommender=SGL
dataset=yelp2018
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.1
ssl_ratio=0.1
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0
2023-05-27 09:31:53.619: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-27 09:34:43.301: [iter 1 : loss : 1.8207 = 0.6930 + 1.1277 + 0.0000, time: 169.682163]
2023-05-27 09:34:47.081: epoch 1:	0.00156782  	0.00299123  	0.00249607  
2023-05-27 09:34:47.081: Find a better model.
2023-05-27 09:37:36.270: [iter 2 : loss : 1.8191 = 0.6928 + 1.1262 + 0.0000, time: 169.169796]
2023-05-27 09:37:39.785: epoch 2:	0.00336622  	0.00667926  	0.00560015  
2023-05-27 09:37:39.785: Find a better model.
2023-05-27 09:40:28.409: [iter 3 : loss : 1.8185 = 0.6924 + 1.1261 + 0.0000, time: 168.604734]
2023-05-27 09:40:31.911: epoch 3:	0.00523411  	0.01111339  	0.00908804  
2023-05-27 09:40:31.911: Find a better model.
2023-05-27 09:43:20.594: [iter 4 : loss : 1.8171 = 0.6909 + 1.1262 + 0.0000, time: 168.662138]
2023-05-27 09:43:24.142: epoch 4:	0.00481883  	0.01049089  	0.00820064  
2023-05-27 09:46:12.947: [iter 5 : loss : 1.8104 = 0.6829 + 1.1275 + 0.0000, time: 168.784541]
2023-05-27 09:46:16.427: epoch 5:	0.00875501  	0.01981767  	0.01611837  
2023-05-27 09:46:16.428: Find a better model.
2023-05-27 09:49:05.790: [iter 6 : loss : 1.7659 = 0.6303 + 1.1355 + 0.0001, time: 169.343761]
2023-05-27 09:49:09.298: epoch 6:	0.01765409  	0.03856289  	0.03207387  
2023-05-27 09:49:09.298: Find a better model.
2023-05-27 09:51:57.745: [iter 7 : loss : 1.6482 = 0.4944 + 1.1534 + 0.0004, time: 168.428210]
2023-05-27 09:52:01.266: epoch 7:	0.02686366  	0.05895476  	0.04861152  
2023-05-27 09:52:01.266: Find a better model.
2023-05-27 09:54:49.156: [iter 8 : loss : 1.4863 = 0.3083 + 1.1771 + 0.0009, time: 167.870813]
2023-05-27 09:54:52.660: epoch 8:	0.02799243  	0.06161702  	0.05085745  
2023-05-27 09:54:52.660: Find a better model.
2023-05-27 09:57:40.443: [iter 9 : loss : 1.3722 = 0.1875 + 1.1833 + 0.0014, time: 167.763588]
2023-05-27 09:57:43.913: epoch 9:	0.02874861  	0.06365998  	0.05241194  
2023-05-27 09:57:43.913: Find a better model.
2023-05-27 10:00:32.281: [iter 10 : loss : 1.3120 = 0.1331 + 1.1771 + 0.0018, time: 168.348558]
2023-05-27 10:00:35.763: epoch 10:	0.02915116  	0.06475411  	0.05342377  
2023-05-27 10:00:35.764: Find a better model.
2023-05-27 10:03:22.001: [iter 11 : loss : 1.2754 = 0.1036 + 1.1696 + 0.0022, time: 166.218993]
2023-05-27 10:03:25.505: epoch 11:	0.02936270  	0.06538705  	0.05399014  
2023-05-27 10:03:25.506: Find a better model.
2023-05-27 10:06:06.911: [iter 12 : loss : 1.2509 = 0.0850 + 1.1634 + 0.0025, time: 161.385820]
2023-05-27 10:06:10.417: epoch 12:	0.02945586  	0.06560559  	0.05426716  
2023-05-27 10:06:10.418: Find a better model.
2023-05-27 10:08:51.711: [iter 13 : loss : 1.2329 = 0.0717 + 1.1584 + 0.0028, time: 161.274747]
2023-05-27 10:08:55.478: epoch 13:	0.02962799  	0.06588849  	0.05445113  
2023-05-27 10:08:55.478: Find a better model.
2023-05-27 10:11:37.439: [iter 14 : loss : 1.2194 = 0.0619 + 1.1544 + 0.0031, time: 161.940912]
2023-05-27 10:11:40.935: epoch 14:	0.02967375  	0.06586232  	0.05454026  
2023-05-27 10:14:22.196: [iter 15 : loss : 1.2093 = 0.0547 + 1.1512 + 0.0034, time: 161.241078]
2023-05-27 10:14:25.722: epoch 15:	0.02964058  	0.06573482  	0.05443943  
2023-05-27 10:17:07.171: [iter 16 : loss : 1.2006 = 0.0484 + 1.1485 + 0.0037, time: 161.428979]
2023-05-27 10:17:10.709: epoch 16:	0.02951903  	0.06545287  	0.05423522  
2023-05-27 10:19:52.039: [iter 17 : loss : 1.1942 = 0.0439 + 1.1463 + 0.0039, time: 161.312149]
2023-05-27 10:19:55.526: epoch 17:	0.02936751  	0.06508873  	0.05397005  
2023-05-27 10:22:37.365: [iter 18 : loss : 1.1886 = 0.0400 + 1.1445 + 0.0042, time: 161.820301]
2023-05-27 10:22:40.895: epoch 18:	0.02924437  	0.06480194  	0.05367682  
2023-05-27 10:25:22.794: [iter 19 : loss : 1.1841 = 0.0368 + 1.1429 + 0.0044, time: 161.870866]
2023-05-27 10:25:26.272: epoch 19:	0.02916542  	0.06453275  	0.05343658  
2023-05-27 10:28:08.035: [iter 20 : loss : 1.1799 = 0.0337 + 1.1416 + 0.0046, time: 161.743701]
2023-05-27 10:28:11.715: epoch 20:	0.02899017  	0.06420367  	0.05311975  
2023-05-27 10:30:53.976: [iter 21 : loss : 1.1768 = 0.0315 + 1.1405 + 0.0048, time: 162.241218]
2023-05-27 10:30:57.562: epoch 21:	0.02885122  	0.06378723  	0.05282687  
2023-05-27 10:33:39.876: [iter 22 : loss : 1.1739 = 0.0294 + 1.1395 + 0.0050, time: 162.293248]
2023-05-27 10:33:43.479: epoch 22:	0.02874705  	0.06344365  	0.05253872  
2023-05-27 10:36:25.530: [iter 23 : loss : 1.1714 = 0.0277 + 1.1386 + 0.0051, time: 162.029495]
2023-05-27 10:36:29.278: epoch 23:	0.02855132  	0.06308184  	0.05228395  
2023-05-27 10:36:29.278: Early stopping is trigger at epoch: 23
2023-05-27 10:36:29.278: best_result@epoch 13:

2023-05-27 10:36:29.278: 		0.0296      	0.0659      	0.0545      
