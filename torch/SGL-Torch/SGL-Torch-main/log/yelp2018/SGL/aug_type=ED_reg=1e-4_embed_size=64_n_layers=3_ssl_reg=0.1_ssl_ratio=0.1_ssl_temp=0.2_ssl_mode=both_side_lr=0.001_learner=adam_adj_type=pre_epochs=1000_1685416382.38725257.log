2023-05-30 11:13:02.388: my pid: 24420
2023-05-30 11:13:02.388: model: model.general_recommender.SGL
2023-05-30 11:13:02.389: Dataset statistics:
Name: yelp2018
The number of users: 31668
The number of items: 38048
The number of ratings: 1561406
Average actions of users: 49.31
Average actions of items: 41.04
The sparsity of the dataset: 99.870412%

The number of training: 1237259
The number of validation: 0
The number of testing: 324147
2023-05-30 11:13:02.389: NeuRec:[NeuRec]:
recommender=SGL
dataset=yelp2018
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.1
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=10
pretrain_flag=0
save_flag=0
2023-05-30 11:13:09.313: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-30 11:16:47.410: [iter 1 : loss : 1.8215 = 0.6931 + 1.1284 + 0.0000, time: 218.085734]
2023-05-30 11:16:50.874: epoch 1:	0.00193569  	0.00386962  	0.00322903  
2023-05-30 11:16:50.874: Find a better model.
2023-05-30 11:20:27.253: [iter 2 : loss : 1.8194 = 0.6930 + 1.1264 + 0.0000, time: 216.358581]
2023-05-30 11:20:30.725: epoch 2:	0.00299358  	0.00602971  	0.00499698  
2023-05-30 11:20:30.725: Find a better model.
2023-05-30 11:24:07.038: [iter 3 : loss : 1.8191 = 0.6929 + 1.1262 + 0.0000, time: 216.294394]
2023-05-30 11:24:10.527: epoch 3:	0.00402937  	0.00831698  	0.00700531  
2023-05-30 11:24:10.527: Find a better model.
2023-05-30 11:27:47.203: [iter 4 : loss : 1.8188 = 0.6927 + 1.1261 + 0.0000, time: 216.655238]
2023-05-30 11:27:50.765: epoch 4:	0.00482832  	0.01014206  	0.00836004  
2023-05-30 11:27:50.765: Find a better model.
2023-05-30 11:31:27.886: [iter 5 : loss : 1.8185 = 0.6924 + 1.1261 + 0.0000, time: 217.099901]
2023-05-30 11:31:31.448: epoch 5:	0.00542516  	0.01177849  	0.00941735  
2023-05-30 11:31:31.448: Find a better model.
2023-05-30 11:35:09.371: [iter 6 : loss : 1.8177 = 0.6914 + 1.1263 + 0.0000, time: 217.902030]
2023-05-30 11:35:12.906: epoch 6:	0.00370094  	0.00837112  	0.00644847  
2023-05-30 11:38:50.698: [iter 7 : loss : 1.8147 = 0.6878 + 1.1268 + 0.0000, time: 217.771662]
2023-05-30 11:38:54.269: epoch 7:	0.00515198  	0.01162196  	0.00913697  
2023-05-30 11:42:32.169: [iter 8 : loss : 1.8022 = 0.6722 + 1.1299 + 0.0001, time: 217.879870]
2023-05-30 11:42:36.008: epoch 8:	0.00940071  	0.02123762  	0.01748798  
2023-05-30 11:42:36.008: Find a better model.
2023-05-30 11:46:14.075: [iter 9 : loss : 1.7524 = 0.6111 + 1.1411 + 0.0002, time: 218.044108]
2023-05-30 11:46:17.625: epoch 9:	0.01510933  	0.03338515  	0.02759511  
2023-05-30 11:46:17.625: Find a better model.
2023-05-30 11:49:55.245: [iter 10 : loss : 1.6661 = 0.5108 + 1.1548 + 0.0005, time: 217.599375]
2023-05-30 11:49:58.932: epoch 10:	0.02524878  	0.05505604  	0.04554168  
2023-05-30 11:49:58.932: Find a better model.
2023-05-30 11:53:37.126: [iter 11 : loss : 1.5449 = 0.3684 + 1.1755 + 0.0010, time: 218.172425]
2023-05-30 11:53:40.725: epoch 11:	0.02753148  	0.06073054  	0.04972765  
2023-05-30 11:53:40.726: Find a better model.
2023-05-30 11:57:18.546: [iter 12 : loss : 1.4260 = 0.2331 + 1.1912 + 0.0017, time: 217.799345]
2023-05-30 11:57:22.113: epoch 12:	0.02830662  	0.06246917  	0.05140077  
2023-05-30 11:57:22.113: Find a better model.
2023-05-30 12:01:00.004: [iter 13 : loss : 1.3530 = 0.1617 + 1.1890 + 0.0023, time: 217.870687]
2023-05-30 12:01:03.616: epoch 13:	0.02908648  	0.06445535  	0.05289031  
2023-05-30 12:01:03.616: Find a better model.
2023-05-30 12:04:41.465: [iter 14 : loss : 1.3094 = 0.1253 + 1.1813 + 0.0029, time: 217.828624]
2023-05-30 12:04:45.538: epoch 14:	0.02946061  	0.06563348  	0.05384492  
2023-05-30 12:04:45.539: Find a better model.
2023-05-30 12:08:23.751: [iter 15 : loss : 1.2802 = 0.1028 + 1.1741 + 0.0034, time: 218.188905]
2023-05-30 12:08:27.329: epoch 15:	0.02974162  	0.06629222  	0.05449528  
2023-05-30 12:08:27.329: Find a better model.
2023-05-30 12:12:05.592: [iter 16 : loss : 1.2590 = 0.0870 + 1.1681 + 0.0038, time: 218.241678]
2023-05-30 12:12:09.147: epoch 16:	0.03000367  	0.06683198  	0.05504793  
2023-05-30 12:12:09.147: Find a better model.
2023-05-30 12:15:47.091: [iter 17 : loss : 1.2433 = 0.0758 + 1.1632 + 0.0043, time: 217.924677]
2023-05-30 12:15:50.730: epoch 17:	0.03017576  	0.06736737  	0.05544171  
2023-05-30 12:15:50.730: Find a better model.
2023-05-30 12:19:28.892: [iter 18 : loss : 1.2309 = 0.0670 + 1.1592 + 0.0047, time: 218.140222]
2023-05-30 12:19:32.598: epoch 18:	0.03034306  	0.06784287  	0.05576723  
2023-05-30 12:19:32.598: Find a better model.
2023-05-30 12:23:10.835: [iter 19 : loss : 1.2211 = 0.0602 + 1.1559 + 0.0050, time: 218.215701]
2023-05-30 12:23:14.371: epoch 19:	0.03044410  	0.06779661  	0.05582469  
2023-05-30 12:26:52.545: [iter 20 : loss : 1.2127 = 0.0540 + 1.1533 + 0.0054, time: 218.151916]
2023-05-30 12:26:56.141: epoch 20:	0.03040623  	0.06772930  	0.05576480  
2023-05-30 12:30:34.191: [iter 21 : loss : 1.2062 = 0.0495 + 1.1510 + 0.0057, time: 218.029291]
2023-05-30 12:30:38.046: epoch 21:	0.03044413  	0.06784651  	0.05576700  
2023-05-30 12:30:38.046: Find a better model.
2023-05-30 12:34:16.913: [iter 22 : loss : 1.2005 = 0.0454 + 1.1490 + 0.0060, time: 218.845271]
2023-05-30 12:34:21.122: epoch 22:	0.03043625  	0.06777424  	0.05573601  
2023-05-30 12:37:59.247: [iter 23 : loss : 1.1958 = 0.0421 + 1.1474 + 0.0063, time: 218.104441]
2023-05-30 12:38:02.846: epoch 23:	0.03030363  	0.06737337  	0.05547671  
2023-05-30 12:41:41.212: [iter 24 : loss : 1.1918 = 0.0392 + 1.1459 + 0.0066, time: 218.343969]
2023-05-30 12:41:44.891: epoch 24:	0.03032888  	0.06732035  	0.05545155  
2023-05-30 12:45:23.414: [iter 25 : loss : 1.1884 = 0.0369 + 1.1446 + 0.0069, time: 218.501512]
2023-05-30 12:45:26.998: epoch 25:	0.03035729  	0.06731968  	0.05540872  
2023-05-30 12:49:04.392: [iter 26 : loss : 1.1850 = 0.0343 + 1.1435 + 0.0072, time: 217.373051]
2023-05-30 12:49:07.991: epoch 26:	0.03018520  	0.06694023  	0.05519402  
2023-05-30 12:52:45.615: [iter 27 : loss : 1.1827 = 0.0327 + 1.1426 + 0.0074, time: 217.604223]
2023-05-30 12:52:49.263: epoch 27:	0.03001627  	0.06652356  	0.05494962  
2023-05-30 12:56:27.508: [iter 28 : loss : 1.1802 = 0.0309 + 1.1417 + 0.0076, time: 218.223107]
2023-05-30 12:56:31.086: epoch 28:	0.02988840  	0.06620648  	0.05472870  
2023-05-30 13:00:09.068: [iter 29 : loss : 1.1780 = 0.0293 + 1.1408 + 0.0079, time: 217.960945]
2023-05-30 13:00:12.673: epoch 29:	0.02976054  	0.06593351  	0.05456730  
2023-05-30 13:03:50.740: [iter 30 : loss : 1.1763 = 0.0280 + 1.1402 + 0.0081, time: 218.046992]
2023-05-30 13:03:54.330: epoch 30:	0.02963582  	0.06558239  	0.05433616  
2023-05-30 13:07:32.247: [iter 31 : loss : 1.1747 = 0.0268 + 1.1395 + 0.0083, time: 217.897043]
2023-05-30 13:07:35.918: epoch 31:	0.02963897  	0.06551676  	0.05420030  
2023-05-30 13:07:35.918: Early stopping is trigger at epoch: 31
2023-05-30 13:07:35.918: best_result@epoch 21:

2023-05-30 13:07:35.919: 		0.0304      	0.0678      	0.0558      
